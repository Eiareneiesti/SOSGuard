<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sound Classification Demo</title>
</head>
<body>
    <div id="main">
        <textarea id="myTextArea01" style="display:none;" rows="10" cols="70">...</textarea> <br> <br> <br>
    </div>

    <audio id="sound" controls></audio>

    <!-- Include edge-impulse-standalone.js -->
    <script src="edge-impulse-standalone.js"></script>

    <!-- Include record.js -->
    <script src="record.js"></script>

    <script>
        let audioContext;
        let soundRecorder;
        let soundData = [];

        // Initialize audio recording
        async function setupAudio() {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            const source = audioContext.createMediaStreamSource(stream);
            soundRecorder = new Recorder(source);
        }

        // Start recording
        function startRecording() {
            soundData = [];
            soundRecorder.record();
        }

        // Stop recording and perform classification
        async function stopRecordingAndClassify() {
            soundRecorder.stop();
            soundRecorder.exportWAV(processAndClassifySound);
        }

        // Process and classify sound data
        async function processAndClassifySound(blob) {
            const reader = new FileReader();
            reader.onloadend = async function () {
                const base64data = reader.result.split(',')[1];
                const classifier = new EdgeImpulseClassifier();
                await classifier.init();
                const results = await classifier.classify(base64data);
                console.log(results);
            };
            reader.readAsDataURL(blob);
        }

        // Recorder.js library
        class Recorder {
            constructor(source) {
                this.context = source.context;
                this.node = this.context.createScriptProcessor(2048, 1, 1);
                const self = this;

                this.node.onaudioprocess = function (e) {
                    if (!self.recording) return;
                    const buffer = e.inputBuffer.getChannelData(0);
                    self.recordBuffer(buffer);
                };

                source.connect(this.node);
                this.node.connect(this.context.destination);
            }

            recordBuffer(buffer) {
                soundData.push(new Float32Array(buffer));
            }

            record() {
                this.recording = true;
            }

            stop() {
                this.recording = false;
            }

            exportWAV(callback) {
                const blob = new Blob([this.encodeWAV()], { type: 'audio/wav' });
                callback(blob);
            }

            encodeWAV() {
                const bufferLength = soundData.length * soundData[0].length * 2;
                const view = new DataView(new ArrayBuffer(44 + bufferLength));
                const sampleRate = this.context.sampleRate;
                let offset = 0;

                const writeString = function (view, offset, string) {
                    for (let i = 0; i < string.length; i++) {
                        view.setUint8(offset + i, string.charCodeAt(i));
                    }
                };

                const floatTo16BitPCM = function (output, offset, input) {
                    for (let i = 0; i < input.length; i++, offset += 2) {
                        const s = Math.max(-1, Math.min(1, input[i]));
                        output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
                    }
                };

                writeString(view, offset, 'RIFF');
                offset += 4;
                view.setUint32(offset, 36 + bufferLength, true);
                offset += 4;
                writeString(view, offset, 'WAVE');
                offset += 4;
                writeString(view, offset, 'fmt ');
                offset += 4;
                view.setUint32(offset, 16, true);
                offset += 4;
                view.setUint16(offset, 1, true);
                offset += 2;
                view.setUint16(offset, 1, true);
                offset += 2;
                view.setUint32(offset, sampleRate, true);
                offset += 4;
                view.setUint32(offset, sampleRate * 2, true);
                offset += 4;
                view.setUint16(offset, 2, true);
                offset += 2;
                view.setUint16(offset, 16, true);
                offset += 2;
                writeString(view, offset, 'data');
                offset += 4;
                view.setUint32(offset, bufferLength, true);
                offset += 4;
                floatTo16BitPCM(view, offset, soundData);
                return view;
            }
        }

        // Setup audio and start recording
        setupAudio().then(() => {
            document.getElementById('sound').srcObject = audioContext;
            document.getElementById('sound').play();
            startRecording();
        });

        // Stop recording and classify on button click
        document.addEventListener('DOMContentLoaded', function () {
            document.getElementById('stopButton').addEventListener('click', function () {
                stopRecordingAndClassify();
            });
        });

    </script>
</body>
</html>
