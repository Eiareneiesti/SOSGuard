<body>
  <div id="main">

    <table border=1 style="position:absolute; left:800px; top:0px;">
      <tr>
        <td>
          Version 0.9.19 <br>

          <div id="description">
            <div id="description-title" style="font-size:30px">Demo Edge Impulse WASM</div>

            <div id="myDiv01" style="font-size:30px"></div>
            <input type=checkbox id="myCheckbox01"><br>
            Stop All Sounds <input type=checkbox id="myCheckbox02sounds"><br>
            <br>
            Microphone: <select id="mySelect" onChange="setupPage()">
              <option value="user">Internal Microphone</option>
              <option value="environment">External Microphone</option>
            </select><br>
          </div>

          <audio id="audio"></audio>

        </td>
      </tr>
    </table>

    <script src="edge-impulse-standalone.js"></script>

    <script>
      let classifier = new EdgeImpulseClassifier();
      classifier.init().then(() => {
        setupPage();
      });

      const setupPage = async () => {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            audio: true,
          });
          const audio = document.getElementById('audio');
          audio.srcObject = stream;
          audio.play();

          processAudio();
        } catch (error) {
          console.error('Error accessing microphone:', error);
        }
      };

      const processAudio = async () => {
        const audio = document.getElementById('audio');
        const audioContext = new AudioContext();
        const source = audioContext.createMediaStreamSource(audio.srcObject);

        // Convert audio to format required by the model
        // (replace with your specific conversion logic)
        const audioData = await convertAudioToFloat32Array(source);

        const results = await classifier.classify(audioData);

        // Display classification results
        displayResults(results);

        processAudio(); // loop for continuous processing
      };

      const convertAudioToFloat32Array = (source) => {
        // Implement your audio conversion logic here
        // based on the model's input requirements

        return new Promise((resolve) => {
          const analyser = new AnalyserNode(audioContext, { fftSize: 2048 });
          source.connect(analyser);

          const dataArray = new Float32Array(analyser.frequencyBinCount);
          analyser.getFloatFrequencyData(dataArray);

          resolve(dataArray);
        });
      };

      const displayResults = (results) => {
        let outputString = '';
        for (const result of results.results) {
          outputString += `${result.label}: ${result.value.toFixed(3)}\n`;
        }
        document.getElementById('myDiv01').innerText = outputString;
      };
    </script>
  </div>
</body>
